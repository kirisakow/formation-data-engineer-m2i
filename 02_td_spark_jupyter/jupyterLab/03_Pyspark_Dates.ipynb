{"cells":[{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"2d8bd23f-d3bd-4e21-b813-e8f63994df73","showTitle":false,"title":""}},"source":["# Manipulation de Date avec Pyspark"]},{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"6aaa1b4c-649c-46d5-8ac7-319471a8d5ed","showTitle":false,"title":""}},"source":["## 1 Rappel sur la manipulation de date avec Python\n","\n","La gestion du temps est trés importante en programmation.\n","\n","> Norme POSIX par exemple\n","\n","\n","En effet, beaucoup de choses peuvent rendre un calcul de temps vite complexe  :\n","\n","  - La gestion des fuseaux horaires\n","  - Les passages aux heures été, hiver"]},{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"b010d21c-bbbe-43de-b4cb-0eea0c02defd","showTitle":false,"title":""}},"source":["### 1.1 Librairie Datetime en Python \n","\n","Pour utiliser les dates et le temps en python nous utilisons la librairie `datetime`\n","\n","Le lien vers la documentation officielle : [Datetime](https://docs.python.org/3/library/datetime.html)"]},{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"e31bce20-1781-4940-b259-087bac30292f","showTitle":false,"title":""}},"source":["#### Définir une date\n","\n","Pour définir une date, nous utilisons la fonction `date`\n","```python\n","datetime.date(<année>,<mois>,<jour>)\n","```"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"d2f5f095-4155-4d22-a902-2d5dea9f328b","showTitle":false,"title":""}},"outputs":[],"source":["# Importation de datetime\n","import datetime\n","\n","# Nous récuperons notre objet qui sera <class 'datetime.date'>\n","date = datetime.date(2020,2,20)\n","\n","print(date)"]},{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"a361f44f-09e9-4b1b-b952-ce7bc1f74fd7","showTitle":false,"title":""}},"source":["#### Définir une date et une heure\n","Pour définir une date et une heure nous utilisons la fonction `datetime` cette fois-ci :\n","\n","Le format est le suivant :\n"," - `datetime.datetime(<annee>,<mois>,<jour>,<heure>,<minute>,<seconde>)`"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"d6e5d541-a260-445f-8320-2a3702dcee5d","showTitle":false,"title":""}},"outputs":[],"source":["# Importation de datetime\n","import datetime\n","\n","date = datetime.datetime(2020,2,20, 11, 10, 33)\n","print(date)"]},{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"71b4e019-35bf-4347-be8c-fa27835bebb4","showTitle":false,"title":""}},"source":["#### Récupération de la date du jour"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"2bc75e41-aa4f-45ec-ab6e-5a0a5d9ce20d","showTitle":false,"title":""}},"outputs":[],"source":["# Importation de datetime\n","import datetime\n","\n","# Grâce à la fonction date.today() nous pouvons récupérer notre date du jour \n","print(datetime.date.today())"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"b6c95067-4ea1-4fde-bf34-c7f179b80616","showTitle":false,"title":""}},"outputs":[],"source":["# Importation de datetime\n","import datetime\n","\n","# En passant par la fonction datetime.today() non seulement nous récupérons la date du jour mais aussi l'heure actuel \n","print(datetime.datetime.today())"]},{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"3a1d523f-5dad-417c-867f-fe26965586d0","showTitle":false,"title":""}},"source":["### 1.2 Les attributs possible sur les dates\n","\n","En passant par la fonction `datetime.datetime` nous récupérons un objet dont la classe est la suivant :\n"," - <class 'datetime.datetime'>\n"," \n","Cela va nous faciliter la récupération de nos informations :\n","- Année -> `.year`\n","- Mois -> `.month`\n","- Jours -> `.day`\n","- Heures -> `.hour`\n","- Secondes -> `.second`"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"11cfb456-b02d-4696-b629-d14eb64ea26e","showTitle":false,"title":""}},"outputs":[],"source":["# Importation de datetime\n","import datetime\n","\n","# Récupérons notre date\n","date = datetime.datetime.now()\n","\n","# si vous voulez savoir le type \n","# print(type(date))\n","\n","# Exemple avec chaque information :\n","print(\"année   \",date.year)\n","print(\"mois    \",date.month)\n","print(\"jour    \",date.day)\n","print(\"heure   \",date.hour)\n","print(\"seconde \",date.second)"]},{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"9a987087-0d5d-4f61-8453-29c738250a75","showTitle":false,"title":""}},"source":["### 1.3 Les fonctions relatives au Date\n","\n","Nous disposons de fonctions déja présentes en python pour le traitement de nos dates"]},{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"e40452d9-eead-4d6a-887d-5fd035267b8b","showTitle":false,"title":""}},"source":["#### Vérification du jour de la semaine"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"c9a98108-fae0-4fec-852d-254431132fd4","showTitle":false,"title":""}},"outputs":[],"source":["# Importation de datetime\n","import datetime\n","\n","# Nous récupérons notre date\n","date = datetime.datetime.today()\n","\n","# Les jours commence le lundi avec l'index 0\n","print(\"jour de la semaine     \",date.weekday())\n","\n","# Les jours commences le lundi avec l'index 1\n","print(\"jour de la semaine iso \",date.isoweekday())\n"]},{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"f18ca4d9-ca12-4cf5-bf94-64c7bbad58db","showTitle":false,"title":""}},"source":["#### Remplacer ou modifier nos dates\n","La fonction replace permet de remplacer une valeur d'une date par une autre."]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"ffaf7b2f-a25b-49ac-a60e-a03277be4031","showTitle":false,"title":""}},"outputs":[],"source":["# Importation de datetime\n","import datetime\n","\n","# Nous récupérons notre date\n","date = datetime.datetime.today()\n","\n","# Affichage de notre date\n","print(date.month)\n","\n","# Modification du mois de notre date\n","dans_trois_mois = date.month + 3\n","print(dans_trois_mois)\n","\n","# Nous définissons directement le mois\n","nouvelle_date = date.replace(month = 5)\n","print(nouvelle_date)"]},{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"2ef070c8-c2fc-46a9-8061-b027fedd2fd6","showTitle":false,"title":""}},"source":["#### Conversion en chaîne de caractères\n","Pour convertir en chaîne de caractères nous utilisons la méthode strftime(<pattern>).\n","\n","Avec les règles:\n","  \n","- `%Y : année YYYY`\n","- `%m : mois entre 01 et 12`\n","- `%d : jour du mois entre 01 et 31`\n","- `%H : heure de 0 à 23`\n","- `%M : minute de 0 à 59`\n","- `%S : seconde de 0 à 59`\n","- `%z : décalage de time zone par rapport à UTC`\n","- `%a : jour de la semaine abrégé, dans la locale`\n","  \n","[Lien vers la documentation officielle](<https://docs.python.org/3/library/datetime.html#strftime-and-strptime-format-codes>)"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"e6fb59a4-6e89-4638-882f-602a5e14f3ba","showTitle":false,"title":""}},"outputs":[],"source":["# Importation de datetime\n","import datetime\n","\n","# Nous récupérons notre date\n","date = datetime.datetime.today()\n","\n","# Exemple de formatage avec l'aide de strftime()\n","print(date.strftime('%d/%m/%Y %H:%M et %S secondes'))"]},{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"25f5538a-0387-4ceb-969f-8fc933ae1edb","showTitle":false,"title":""}},"source":["### 1.4 Les opérations entre dates"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"7d8daad8-a0a3-420b-9bd5-c0826828ae35","showTitle":false,"title":""}},"outputs":[],"source":["# Importation de datetime\n","import datetime\n","\n","# Instancions une date \n","date1 = datetime.datetime(2021,1,2,5)\n","\n","# Récupérons la date d'aujourd'hui\n","date2 = datetime.datetime.now()\n","\n","# Calculons maintenant la différence entre le deux\n","delta_entre_les_dates = date2-date1\n","\n","\n","print(\"delta\", type(delta_entre_les_dates))\n","print(\"en jour\", delta_entre_les_dates.days)\n","print(\"en secondes\", delta_entre_les_dates.seconds)"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"fa90d5dd-845e-480e-b477-a141d91c18c5","showTitle":false,"title":""}},"outputs":[],"source":["# Importation de datetime\n","import datetime\n","\n","# On peut également prévoir le delta directement par la fonction timedelta()\n","delta_time = datetime.timedelta(days=30)\n","\n","# Si on affiche notre delta nous constaterons qu'il contient juste \"30 days, 0:00:00\"\n","print(delta_time)\n","\n","# On peut donc directement par la suite manipuler cela\n","# Exemple :\n","# Affichage de la date du jour moins notre delta\n","print(datetime.datetime.now()-delta_time)"]},{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"3e19f554-329a-4666-b050-7e90340453df","showTitle":false,"title":""}},"source":["## 2 Rappel sur les dates en SQL"]},{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"b1a793a3-6650-4761-b14b-903760349859","showTitle":false,"title":""}},"source":["### 2.1 Obtenir la date du jour\n","\n","Pour simplifier les requêtes et les rendre dynamiques, SQL nous fournit une fonction `NOW()` qui donne la date du jour.\n","\n","Cette date répond au format **DATETIME** pas forcément lisible pour l'humain mais compréhensible pour SQL.  \n","\n","SQL peut donc faire des comparaisons et utiliser directement le résultat de cette fonction.\n","\n","[lien vers la documentation officiel](https://docs.databricks.com/spark/latest/spark-sql/language-manual/sql-ref-functions-builtin.html#date-timestamp-and-interval-functions)"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"4ef8f342-fa4a-4280-a039-d0d82be428b7","showTitle":false,"title":""}},"outputs":[],"source":["%sql\n","\n","SELECT NOW();\n"]},{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"b2009701-f4b5-4f5b-93b2-41ca980e3387","showTitle":false,"title":""}},"source":["### 2.2 Transformer une date\n","Cette date peut être rendue lisible avec d'autres fonctions qui extraient des informations de la date.\n","- `MICROSECOND()` extrait la microseconde d'une date\n","- `SECOND()` extrait la seconde d'une date\n","- `MINUTE()` extrait la minute d'une date\n","- `HOUR()` extrait l'heure d'une date\n","- `DAYOFWEEK()` extrait le numéro de jour de la semaine (Dimanche étant le 1er jour et Samedi le 7ème jour)\n","- `DAY()` extrait le jour d'une date\n","- `MONTH()` extrait le mois d'une date\n","- `YEAR()` extrait l'année d'une date\n","- `DAYOFYEAR()` extrait le jour de l'année d'une date\n","- `QUARTER()` extrait le trimestre d'une date"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"707e36f0-416e-4c4d-8040-be92d746865f","showTitle":false,"title":""}},"outputs":[],"source":["%sql\n","\n","-- Exemple des fonctions citées juste ci-dessus\n","SELECT\n","  SECOND(NOW()),\n","  MINUTE(NOW()),\n","  HOUR(NOW()),\n","  DAYOFWEEK(NOW()),\n","  DAY(NOW()),\n","  MONTH(NOW()),\n","  YEAR(NOW()),\n","  DAYOFYEAR(NOW()),\n","  QUARTER(NOW());"]},{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"281e3f09-97aa-4026-8f3e-e4d10728fc4a","showTitle":false,"title":""}},"source":["### 2.3 Formater une date\n","Une autre façon de transformer une date est de passer par un formatage avec la méthode `DATE_FORMAT()`.\n","\n","Pour consulter la liste complète des pattern pour le format: [Format de date sur Databrick](https://docs.databricks.com/spark/latest/spark-sql/language-manual/sql-ref-datetime-pattern.html)"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"76bbb013-2ed6-4ad0-99c2-aa54457969d0","showTitle":false,"title":""}},"outputs":[],"source":["%sql\n","-- Exemple de formattage de date \n","    -- Nous selectionnons juste l'année dans la premiere colonne  (l'année entiere)\n","    -- Nous selectionnons juste les deux derniers chiffres de l'année dans la seconde colonne\n","    -- Nous selectionnons juste le jour, le chiffre du mois et l'année en entière\n","SELECT date_format(NOW(), 'y'), date_format(NOW(), 'yy'), date_format(NOW(), 'd-MM-y');"]},{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"7305bd31-4e17-446c-873b-c12786e5d8e6","showTitle":false,"title":""}},"source":["### 2.4 Opération sur les dates\n","Il est possible d'ajouter ou soustraire des dates en elles. Ceci est possible grâce au format DATETIME qui attribut une valeur numérique aux dates.\n","\n","`date_sub` et `date_add` permettent respectivement de supprimer et d'ajouter des jours à une date."]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"23a97a6a-894f-4abf-8cdd-86d47a64a719","showTitle":false,"title":""}},"outputs":[],"source":["%sql\n","-- Dans cet exemple simple ne récupérons la date du jour à laquelle nous ajoutons 15 jours par le `DAY`\n","SELECT DAY(date_add(NOW(), 15))"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"86e1ed64-560e-465b-b286-d55fa14b9892","showTitle":false,"title":""}},"outputs":[],"source":["%sql\n","-- Exemple concret avec la récupération les résultats des 7 derniers jours:\n","SELECT DISTINCT dtjour FROM bgescaf.gssdpfts WHERE dtjour BETWEEN date_sub('2020-02-02', 7) AND '2020-02-02';"]},{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"e94064ab-b976-48db-b29a-fdb4118cf7d3","showTitle":false,"title":""}},"source":["## 3 Manipulation des dates en Pyspark \n","\n","Pyspark nous donne accés aux différentes méthodes que l'on vient de rappeler ci-dessus.  \n","\n","Mais il nous en propose d'autres aussi !"]},{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"f4d1b3e2-f0f0-454b-9790-b523e06a24eb","showTitle":false,"title":""}},"source":["### Récupération de la date en Pyspark"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"13860f45-56e6-4e2b-bea0-7a04e145c367","showTitle":false,"title":""}},"outputs":[{"data":{"text/html":["<style scoped>\n","  .ansiout {\n","    display: block;\n","    unicode-bidi: embed;\n","    white-space: pre-wrap;\n","    word-wrap: break-word;\n","    word-break: break-all;\n","    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n","    font-size: 13px;\n","    color: #555;\n","    margin-left: 4px;\n","    line-height: 19px;\n","  }\n","</style>\n","<div class=\"ansiout\"></div>"]},"metadata":{"application/vnd.databricks.v1+output":{"addedWidgets":{},"arguments":{},"data":"<div class=\"ansiout\"></div>","datasetInfos":[],"metadata":{},"removedWidgets":[],"type":"html"}},"output_type":"display_data"},{"data":{"text/html":["<style scoped>\n","  .ansiout {\n","    display: block;\n","    unicode-bidi: embed;\n","    white-space: pre-wrap;\n","    word-wrap: break-word;\n","    word-break: break-all;\n","    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n","    font-size: 13px;\n","    color: #555;\n","    margin-left: 4px;\n","    line-height: 19px;\n","  }\n","</style>\n","<div class=\"ansiout\"><span class=\"ansi-red-fg\">---------------------------------------------------------------------------</span>\n","<span class=\"ansi-red-fg\">NameError</span>                                 Traceback (most recent call last)\n","<span class=\"ansi-green-fg\">&lt;command-4070734208937429&gt;</span> in <span class=\"ansi-cyan-fg\">&lt;module&gt;</span>\n","<span class=\"ansi-green-intense-fg ansi-bold\">      6</span> \n","<span class=\"ansi-green-intense-fg ansi-bold\">      7</span> <span class=\"ansi-red-fg\"># Ajoutons à notre colonne date_jour la date d&#39;aujourd&#39;hui</span>\n","<span class=\"ansi-green-fg\">----&gt; 8</span><span class=\"ansi-red-fg\"> </span>mon_dataframe<span class=\"ansi-blue-fg\">.</span>select<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#34;date_jour&#34;</span><span class=\"ansi-blue-fg\">,</span>current_date<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">.</span>alias<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#34;current_date&#34;</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">.</span>show<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-cyan-fg\">1</span><span class=\"ansi-blue-fg\">)</span>\n","\n","<span class=\"ansi-red-fg\">NameError</span>: name &#39;current_date&#39; is not defined</div>"]},"metadata":{"application/vnd.databricks.v1+output":{"arguments":{},"data":"<div class=\"ansiout\"><span class=\"ansi-red-fg\">---------------------------------------------------------------------------</span>\n<span class=\"ansi-red-fg\">NameError</span>                                 Traceback (most recent call last)\n<span class=\"ansi-green-fg\">&lt;command-4070734208937429&gt;</span> in <span class=\"ansi-cyan-fg\">&lt;module&gt;</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      6</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">      7</span> <span class=\"ansi-red-fg\"># Ajoutons à notre colonne date_jour la date d&#39;aujourd&#39;hui</span>\n<span class=\"ansi-green-fg\">----&gt; 8</span><span class=\"ansi-red-fg\"> </span>mon_dataframe<span class=\"ansi-blue-fg\">.</span>select<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#34;date_jour&#34;</span><span class=\"ansi-blue-fg\">,</span>current_date<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">.</span>alias<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#34;current_date&#34;</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">.</span>show<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-cyan-fg\">1</span><span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-red-fg\">NameError</span>: name &#39;current_date&#39; is not defined</div>","errorSummary":"<span class=\"ansi-red-fg\">NameError</span>: name &#39;current_date&#39; is not defined","errorTraceType":"html","metadata":{},"type":"ipynbError"}},"output_type":"display_data"}],"source":["# Nous allons récupérer notre date de ce jour grâce à la fonction current_date()\n","\n","# Récupérons dans un premier temps notre dataframe\n","# Vous remarquerez que l'on ne va utiliser que la colonne date_jour pour la manipulation de dates\n","mon_dataframe = spark.table(\"formation.arrivees\").select(\"date_jour\")\n","\n","# Ajoutons à notre colonne date_jour la date d'aujourd'hui\n","mon_dataframe.select(\"date_jour\",current_date().alias(\"current_date\")).show(1)\n"]},{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"cbe16323-e100-46cf-a4de-fd4bb84083f1","showTitle":false,"title":""}},"source":["### Manipulation du format en Pyspark\n","\n","Pyspark nous donne la main sur le format de date que l'on souhaite manipuler grâce à la fonction `date_format()`"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"90898c7f-c43d-4144-a236-b7cecf731abd","showTitle":false,"title":""}},"outputs":[{"data":{"text/html":["<style scoped>\n","  .ansiout {\n","    display: block;\n","    unicode-bidi: embed;\n","    white-space: pre-wrap;\n","    word-wrap: break-word;\n","    word-break: break-all;\n","    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n","    font-size: 13px;\n","    color: #555;\n","    margin-left: 4px;\n","    line-height: 19px;\n","  }\n","</style>\n","<div class=\"ansiout\">+-------------------+-----------+\n","          date_jour|date_format|\n","+-------------------+-----------+\n","2019-05-20 00:00:00| 05-20-2019|\n","+-------------------+-----------+\n","only showing top 1 row\n","\n","</div>"]},"metadata":{"application/vnd.databricks.v1+output":{"addedWidgets":{},"arguments":{},"data":"<div class=\"ansiout\">+-------------------+-----------+\n|          date_jour|date_format|\n+-------------------+-----------+\n|2019-05-20 00:00:00| 05-20-2019|\n+-------------------+-----------+\nonly showing top 1 row\n\n</div>","datasetInfos":[],"metadata":{},"removedWidgets":[],"type":"html"}},"output_type":"display_data"}],"source":["from pyspark.sql.functions import *\n","# Récupérons dans un premier temps notre dataframes\n","mon_dataframe = spark.table(\"formation.arrivees\").select(\"date_jour\")\n","\n","# Nous allons ajouter dans notre ci-dessous une colonne qui\n","# contiendra la date présente dans la colonne \"date_jour\" mais dans un format différent\n","mon_dataframe.select(\"date_jour\",date_format(col(\"date_jour\"), \"MM-dd-yyyy\").alias(\"date_format\")).show(1)"]},{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"38971699-8652-4ce6-83ae-1a38898d7753","showTitle":false,"title":""}},"source":["### Manipulation du type en Pyspark\n","\n","Pyspark nous permet également de manipuler le type de nos données afin de par exemple transformer un string en date."]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"b6b8613f-f48d-4a2d-9bc5-87a24f8a3cf4","showTitle":false,"title":""}},"outputs":[{"data":{"text/html":["<style scoped>\n","  .ansiout {\n","    display: block;\n","    unicode-bidi: embed;\n","    white-space: pre-wrap;\n","    word-wrap: break-word;\n","    word-break: break-all;\n","    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n","    font-size: 13px;\n","    color: #555;\n","    margin-left: 4px;\n","    line-height: 19px;\n","  }\n","</style>\n","<div class=\"ansiout\">root\n","-- id: string (nullable = true)\n","-- date_string: string (nullable = true)\n","\n","+---+-----------+\n"," id|date_string|\n","+---+-----------+\n","  1| 2022-09-09|\n","+---+-----------+\n","\n","root\n","-- date_string: string (nullable = true)\n","-- date_date: date (nullable = true)\n","\n","+-----------+----------+\n","date_string| date_date|\n","+-----------+----------+\n"," 2022-09-09|2022-09-09|\n","+-----------+----------+\n","\n","</div>"]},"metadata":{"application/vnd.databricks.v1+output":{"addedWidgets":{},"arguments":{},"data":"<div class=\"ansiout\">root\n |-- id: string (nullable = true)\n |-- date_string: string (nullable = true)\n\n+---+-----------+\n| id|date_string|\n+---+-----------+\n|  1| 2022-09-09|\n+---+-----------+\n\nroot\n |-- date_string: string (nullable = true)\n |-- date_date: date (nullable = true)\n\n+-----------+----------+\n|date_string| date_date|\n+-----------+----------+\n| 2022-09-09|2022-09-09|\n+-----------+----------+\n\n</div>","datasetInfos":[],"metadata":{},"removedWidgets":[],"type":"html"}},"output_type":"display_data"}],"source":["# Nous réalisons nos imports\n","from pyspark.sql import SparkSession\n","from pyspark.sql.functions import *\n","\n","# Nous créons une session spark\n","spark_session = SparkSession.builder.getOrCreate()\n","\n","# Nous allons nous même rentrer les données\n","donnee =[[\"1\",\"2022-09-09\"]]\n","# Puis l'on créer notre dataframe\n","mon_dataframe=spark.createDataFrame(donnee,[\"id\",\"date_string\"])\n","\n","# Vérifions\n","mon_dataframe.printSchema()\n","mon_dataframe.show()\n","\n","# Nous récupérons la date (type string) de ma première colonne afin de créer une nouvelle colonne qui aura la date (type date)\n","mon_dataframe2 = mon_dataframe.select(\"date_string\",to_date(col(\"date_string\"), \"yyyy-MM-dd\").alias(\"date_date\"))\n","\n","# Nous affichons notre Schema afin de vérifier \n","# On pourra constater que ma deuxieme colonne est bien de type date\n","mon_dataframe2.printSchema()\n","mon_dataframe2.show()"]},{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"df7dcf06-926b-4a0e-8a56-61f4db5c5410","showTitle":false,"title":""}},"source":["### Calcul de date\n","\n","Deux méthodes peuvent nous servir à calculer des intervalles de dates :\n","- `datediff()`\n","- `months_between()`"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"98ede1f2-bd69-4163-9ddd-01e0531ade6f","showTitle":false,"title":""}},"outputs":[{"data":{"text/html":["<style scoped>\n","  .ansiout {\n","    display: block;\n","    unicode-bidi: embed;\n","    white-space: pre-wrap;\n","    word-wrap: break-word;\n","    word-break: break-all;\n","    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n","    font-size: 13px;\n","    color: #555;\n","    margin-left: 4px;\n","    line-height: 19px;\n","  }\n","</style>\n","<div class=\"ansiout\">+---+----------+\n"," id|      date|\n","+---+----------+\n","  1|2022-07-09|\n","+---+----------+\n","\n","+----------+---------------+\n","      date|difference_date|\n","+----------+---------------+\n","2022-07-09|            101|\n","+----------+---------------+\n","\n","+----------+---------------+\n","      date|difference_mois|\n","+----------+---------------+\n","2022-07-09|     3.29032258|\n","+----------+---------------+\n","\n","</div>"]},"metadata":{"application/vnd.databricks.v1+output":{"addedWidgets":{},"arguments":{},"data":"<div class=\"ansiout\">+---+----------+\n| id|      date|\n+---+----------+\n|  1|2022-07-09|\n+---+----------+\n\n+----------+---------------+\n|      date|difference_date|\n+----------+---------------+\n|2022-07-09|            101|\n+----------+---------------+\n\n+----------+---------------+\n|      date|difference_mois|\n+----------+---------------+\n|2022-07-09|     3.29032258|\n+----------+---------------+\n\n</div>","datasetInfos":[],"metadata":{},"removedWidgets":[],"type":"html"}},"output_type":"display_data"}],"source":["# Reprenons notre exemple précédent\n","# Nous réalisons nos imports\n","from pyspark.sql import SparkSession\n","from pyspark.sql.functions import *\n","\n","# Nous créons une session spark\n","spark_session = SparkSession.builder.getOrCreate()\n","\n","# Nous allons nous même rentrer les données\n","donnee =[[\"1\",\"2022-07-09\"]]\n","# Puis l'on créer notre dataframe\n","mon_dataframe=spark.createDataFrame(donnee,[\"id\",\"date\"])\n","\n","mon_dataframe.show()\n","\n","# Faisons maintenant la différence avec la date actuel et affichons cela dans une colonne grâce à datediff()\n","mon_dataframe.select(\"date\",datediff(current_date(),\"date\").alias(\"difference_date\")).show()\n","\n","# Nous pouvons également calculer la différence en mois\n","mon_dataframe.select(\"date\",months_between(current_date(),\"date\").alias(\"difference_mois\")).show()\n","\n","#On pourrait également diviser par 12 pour avoir le nombre d'année\n","# .withColumn(\"yearsDiff\",months_between(current_date(),col(\"date\"))/lit(12))"]},{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"f1f53703-38ed-4e27-8adf-133e21239477","showTitle":false,"title":""}},"source":["### Modification de date\n","\n","Nous pouvons également comme vu précédemment modifier une date grâce aux fonctions :\n","\n","- `add_months()`\n","- `date_add()`\n","- `date_sub()`"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"71e01506-d9ce-4454-acb2-b7427e035267","showTitle":false,"title":""}},"outputs":[{"data":{"text/html":["<style scoped>\n","  .ansiout {\n","    display: block;\n","    unicode-bidi: embed;\n","    white-space: pre-wrap;\n","    word-wrap: break-word;\n","    word-break: break-all;\n","    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n","    font-size: 13px;\n","    color: #555;\n","    margin-left: 4px;\n","    line-height: 19px;\n","  }\n","</style>\n","<div class=\"ansiout\">+---+----------+\n"," id|      date|\n","+---+----------+\n","  1|2022-09-09|\n","+---+----------+\n","\n","+----------+---------------+\n","      date|add_month_3mois|\n","+----------+---------------+\n","2022-09-09|     2022-12-09|\n","+----------+---------------+\n","\n","+----------+--------------+\n","      date|date_add_3mois|\n","+----------+--------------+\n","2022-09-09|    2022-09-12|\n","+----------+--------------+\n","\n","+----------+--------------+\n","      date|date_sub_3mois|\n","+----------+--------------+\n","2022-09-09|    2022-09-06|\n","+----------+--------------+\n","\n","</div>"]},"metadata":{"application/vnd.databricks.v1+output":{"addedWidgets":{},"arguments":{},"data":"<div class=\"ansiout\">+---+----------+\n| id|      date|\n+---+----------+\n|  1|2022-09-09|\n+---+----------+\n\n+----------+---------------+\n|      date|add_month_3mois|\n+----------+---------------+\n|2022-09-09|     2022-12-09|\n+----------+---------------+\n\n+----------+--------------+\n|      date|date_add_3mois|\n+----------+--------------+\n|2022-09-09|    2022-09-12|\n+----------+--------------+\n\n+----------+--------------+\n|      date|date_sub_3mois|\n+----------+--------------+\n|2022-09-09|    2022-09-06|\n+----------+--------------+\n\n</div>","datasetInfos":[],"metadata":{},"removedWidgets":[],"type":"html"}},"output_type":"display_data"}],"source":["# Reprenons notre exemple précédent\n","# Nous réalisons nos imports\n","from pyspark.sql import SparkSession\n","from pyspark.sql.functions import *\n","\n","# Nous créons une session spark\n","spark_session = SparkSession.builder.getOrCreate()\n","\n","# Nous allons nous même rentrer les données\n","donnee =[[\"1\",\"2022-09-09\"]]\n","# Puis l'on créer notre dataframe\n","mon_dataframe=spark.createDataFrame(donnee,[\"id\",\"date\"])\n","\n","mon_dataframe.show()\n","\n","# Ajout de mois avec add_months()\n","mon_dataframe.select(\"date\",add_months(\"date\",3).alias(\"add_month_3mois\")).show()\n","\n","# Ajout avec date_add()\n","mon_dataframe.select(\"date\",date_add(\"date\",3).alias(\"date_add_3mois\")).show()\n","\n","# Soustraction avec date_sub()\n","mon_dataframe.select(\"date\",date_sub(\"date\",3).alias(\"date_sub_3mois\")).show()"]},{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"06b0f75c-b0b8-4b2f-9655-d8c1dc5cbbb0","showTitle":false,"title":""}},"source":["De nombreuse méthodes sont encore disponible.  \n","Voici une liste partielle  :\n","- `year()`\n","- `month()`\n","- `month()`\n","- `next_day()`\n","- `weekofyear()`\n","- `dayofweek()`\n","- `dayofmonth()`\n","- `dayofyear()`"]},{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"db6f8eb3-a88e-4cae-89d2-1c10eb518ca2","showTitle":true,"title":""}},"source":["## 4 Manipulation des timestamps en Pyspark\n","\n","Nous pouvons également manipuler les timestamps avec Pyspark"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"f6a6bcb3-0c98-416e-a251-fead2343e420","showTitle":false,"title":""}},"outputs":[{"data":{"text/html":["<style scoped>\n","  .ansiout {\n","    display: block;\n","    unicode-bidi: embed;\n","    white-space: pre-wrap;\n","    word-wrap: break-word;\n","    word-break: break-all;\n","    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n","    font-size: 13px;\n","    color: #555;\n","    margin-left: 4px;\n","    line-height: 19px;\n","  }\n","</style>\n","<div class=\"ansiout\">+-------------------+\n","          date_jour|\n","+-------------------+\n","2019-05-20 00:00:00|\n","+-------------------+\n","only showing top 1 row\n","\n","+-------------------+---------------------+\n","          date_jour|timestamp_date_actuel|\n","+-------------------+---------------------+\n","2019-05-20 00:00:00| 2022-10-17 12:16:...|\n","+-------------------+---------------------+\n","only showing top 1 row\n","\n","+-------------------+------+-------+--------+\n","          date_jour|heures|minutes|secondes|\n","+-------------------+------+-------+--------+\n","2019-05-20 00:00:00|     0|      0|       0|\n","+-------------------+------+-------+--------+\n","only showing top 1 row\n","\n","</div>"]},"metadata":{"application/vnd.databricks.v1+output":{"addedWidgets":{},"arguments":{},"data":"<div class=\"ansiout\">+-------------------+\n|          date_jour|\n+-------------------+\n|2019-05-20 00:00:00|\n+-------------------+\nonly showing top 1 row\n\n+-------------------+---------------------+\n|          date_jour|timestamp_date_actuel|\n+-------------------+---------------------+\n|2019-05-20 00:00:00| 2022-10-17 12:16:...|\n+-------------------+---------------------+\nonly showing top 1 row\n\n+-------------------+------+-------+--------+\n|          date_jour|heures|minutes|secondes|\n+-------------------+------+-------+--------+\n|2019-05-20 00:00:00|     0|      0|       0|\n+-------------------+------+-------+--------+\nonly showing top 1 row\n\n</div>","datasetInfos":[],"metadata":{},"removedWidgets":[],"type":"html"}},"output_type":"display_data"}],"source":["from pyspark.sql.functions import *\n","\n","# Récupérons dans un premier temps notre dataframes\n","mon_dataframe = spark.table(\"formation.arrivees\").select(\"date_jour\")\n","\n","mon_dataframe.show(1)\n","\n","# Nous pouvons récuperer la date et l'heure sous forme de timestamp grâce ) current_timestamp()\n","mon_dataframe.select(\"date_jour\",current_timestamp().alias(\"timestamp_date_actuel\")).show(1)\n","\n","\n","# Nous pouvons également manipuler les heures,minutes et secondes\n","mon_dataframe.select(\"date_jour\",hour(\"date_jour\").alias(\"heures\"),minute(\"date_jour\").alias(\"minutes\"),second(\"date_jour\").alias(\"secondes\")).show(1)"]}],"metadata":{"application/vnd.databricks.v1+notebook":{"dashboards":[],"language":"python","notebookMetadata":{"pythonIndentUnit":4},"notebookName":"03_Pyspark_Dates","notebookOrigID":2139969005562218,"widgets":{}},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.9 (tags/v3.10.9:1dd9be6, Dec  6 2022, 20:01:21) [MSC v.1934 64 bit (AMD64)]"},"vscode":{"interpreter":{"hash":"bd6f263fc755eebb9705a1037789dd7cb01391d5841f7a8e7a78f9bd6260bb09"}}},"nbformat":4,"nbformat_minor":0}
